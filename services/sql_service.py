"""SQL Generation Service - Debug Version"""
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from config.prompts import SQL_GENERATION_PROMPT
from config.settings import MODEL_CONFIG
import re

class SQLService:
    """SQL ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        print("ğŸ”„ SQLCoder ë¡œë”©...")
        
        self.tokenizer = AutoTokenizer.from_pretrained(
            MODEL_CONFIG['model_id'],
            trust_remote_code=True
        )
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id
        
        model = AutoModelForCausalLM.from_pretrained(
            MODEL_CONFIG['model_id'],
            torch_dtype=torch.float16,
            device_map=MODEL_CONFIG['device_map'],
            load_in_8bit=MODEL_CONFIG['load_in_8bit'],
            trust_remote_code=True
        )
        
        self.model = model
        print("âœ… SQLCoder ë¡œë“œ ì™„ë£Œ!")
    
    def generate(self, question, tables, hints=None):
        """SQL ìƒì„±"""
        try:
            schema = "\n\n".join([t["schema"] for t in tables])
            
            prompt = SQL_GENERATION_PROMPT.format(
                question=question,
                schema=schema
            )
            
            if hints:
                hints_text = "\n\n### Additional Context\n"
                for hint in hints:
                    hints_text += f"{hint}\n"
                prompt = prompt + hints_text
            
            prompt_text = str(prompt).strip()
            
            inputs = self.tokenizer.encode(
                prompt_text,
                return_tensors="pt",
                truncation=True,
                max_length=2048,
                add_special_tokens=True
            )
            
            inputs = inputs.to(self.model.device)
            
            with torch.no_grad():
                outputs = self.model.generate(
                    inputs,
                    max_new_tokens=MODEL_CONFIG['max_new_tokens'],
                    temperature=MODEL_CONFIG['temperature'],
                    do_sample=True,
                    pad_token_id=self.tokenizer.pad_token_id,
                    eos_token_id=self.tokenizer.eos_token_id
                )
            
            result = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ğŸ” ë””ë²„ê¹… ì¶œë ¥
            print(f"\n   ğŸ“„ ìƒì„± ê²°ê³¼ ê¸¸ì´: {len(result)} chars")
            
            # Answer ì„¹ì…˜ ì°¾ê¸°
            if "### Answer" in result:
                answer_part = result.split("### Answer")[-1]
                print(f"   ğŸ“ Answer ì„¹ì…˜ ({len(answer_part)} chars):")
                print("   " + "="*60)
                print(answer_part[:800])  # ì•ë¶€ë¶„ 800ì
                print("   " + "="*60)
            else:
                print(f"   ğŸ“ ì „ì²´ ê²°ê³¼ ë§ˆì§€ë§‰ 800ì:")
                print("   " + "="*60)
                print(result[-800:])
                print("   " + "="*60)
            
            # SQL ì¶”ì¶œ
            sql = self._extract_sql(result)
            
            return sql
            
        except Exception as e:
            print(f"\n   âŒ ì—ëŸ¬: {e}")
            import traceback
            traceback.print_exc()
            return f"SELECT * FROM {tables[0]['name']} LIMIT 10"
    
    def _extract_sql(self, text):
        """SQL ì¶”ì¶œ"""
        # Answer ì„¹ì…˜ë§Œ ì‚¬ìš©
        if "### Answer" in text:
            text = text.split("### Answer")[-1]
        
        # SELECT ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ê´€, ê³µë°± ê´€ëŒ€)
        pattern = r'SELECT.+?FROM.+?(?:WHERE.+?)?(?:;|\n\n|```|$)'
        matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
        
        print(f"\n   ğŸ” ì •ê·œì‹ ë§¤ì¹­: {len(matches)}ê°œ")
        
        if matches:
            for i, m in enumerate(matches):
                clean = re.sub(r'\s+', ' ', m[:100])
                print(f"      {i+1}. {clean}...")
        
        if not matches:
            # Fallback: ìˆ˜ë™ ê²€ìƒ‰
            print(f"   âš ï¸  ì •ê·œì‹ ì‹¤íŒ¨, ìˆ˜ë™ ê²€ìƒ‰...")
            
            lines = text.split('\n')
            for i, line in enumerate(lines):
                if 'SELECT' in line.upper():
                    print(f"      Line {i}: {line[:80]}")
            
            raise ValueError("No SELECT found")
        
        # ê°€ì¥ ê¸´ ë§¤ì¹­
        sql = max(matches, key=len)
        
        # ì •ë¦¬
        sql = sql.replace(';', '').strip()
        sql = sql.split('```')[0]  # ì½”ë“œ ë¸”ë¡ ì¢…ë£Œ ì œê±°
        sql = re.sub(r'\s+', ' ', sql)
        
        print(f"   âœ… ì¶”ì¶œ ì„±ê³µ: {sql[:80]}...")
        
        return sql
