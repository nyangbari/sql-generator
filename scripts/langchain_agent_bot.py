#!/usr/bin/env python3
# langchain_agent_bot.py
# ìŠ¤í‚¤ë§ˆ ìºì‹œ ê°•ì œ ìƒˆë¡œê³ ì¹¨

import os
import sys
import torch
from dotenv import load_dotenv
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from peft import PeftModel
from langchain_huggingface import HuggingFacePipeline
from langchain_community.utilities.sql_database import SQLDatabase
from langchain_community.agent_toolkits.sql.base import create_sql_agent
from sqlalchemy import create_engine, inspect, text

load_dotenv()

class FreshSchemaSQLDatabase(SQLDatabase):
    """í•­ìƒ ìµœì‹  ìŠ¤í‚¤ë§ˆë¥¼ ê°€ì ¸ì˜¤ëŠ” DB"""
    
    WRITE_KEYWORDS = [
        'INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 
        'ALTER', 'TRUNCATE', 'REPLACE', 'MERGE'
    ]
    
    def __init__(self, *args, **kwargs):
        # ìƒ˜í”Œ ë°ì´í„° 0ê°œ
        kwargs['sample_rows_in_table_info'] = 0
        super().__init__(*args, **kwargs)
        
        # ìºì‹œ ë¬´íš¨í™”
        self._sample_rows_in_table_info = 0
        self._indexes_in_table_info = False
    
    def get_table_info(self, table_names=None):
        """ì‹¤ì œ DBì—ì„œ ì§ì ‘ ìŠ¤í‚¤ë§ˆ ê°€ì ¸ì˜¤ê¸°"""
        
        if table_names is None:
            table_names = self.get_usable_table_names()
        
        # Inspectorë¡œ ì‹¤ì œ ìŠ¤í‚¤ë§ˆ í™•ì¸
        inspector = inspect(self._engine)
        
        all_table_info = []
        
        for table_name in table_names:
            # ì‹¤ì œ ì»¬ëŸ¼ ì •ë³´
            columns = inspector.get_columns(table_name)
            pk_constraint = inspector.get_pk_constraint(table_name)
            pk_columns = pk_constraint.get('constrained_columns', [])
            
            # CREATE TABLE ë¬¸ ìƒì„±
            create_table = f"\nCREATE TABLE {table_name} (\n"
            
            col_lines = []
            for col in columns:
                col_type = str(col['type'])
                nullable = "" if col['nullable'] else " NOT NULL"
                pk = " PRIMARY KEY" if col['name'] in pk_columns else ""
                
                col_lines.append(
                    f"    {col['name']} {col_type}{nullable}{pk}"
                )
            
            create_table += ",\n".join(col_lines)
            create_table += "\n)"
            
            all_table_info.append(create_table)
            
            print(f"\nðŸ“‹ [{table_name}] ì‹¤ì œ ìŠ¤í‚¤ë§ˆ í™•ì¸:")
            print(create_table)
        
        return "\n\n".join(all_table_info)
    
    def run(self, command: str, fetch: str = "all", **kwargs):
        """SQL ì‹¤í–‰"""
        
        sql_upper = command.upper().strip()
        
        # ë³´ì•ˆ ì²´í¬
        for keyword in self.WRITE_KEYWORDS:
            if keyword in sql_upper:
                raise ValueError(f"ðŸš« {keyword} ì°¨ë‹¨!")
        
        if not any(sql_upper.startswith(k) for k in ['SELECT', 'SHOW', 'DESCRIBE', 'EXPLAIN']):
            raise ValueError("ðŸš« SELECTë§Œ í—ˆìš©")
        
        print(f"\nðŸ” [ì‹¤í–‰ SQL]\n{command}\n")
        
        # ì‹¤í–‰
        result = super().run(command, fetch=fetch, **kwargs)
        
        print(f"ðŸ“Š [DB ê²°ê³¼]\n{result}\n")
        
        return result

class LangChainAgentBot:
    def __init__(self, model_path):
        print("="*70)
        print("ðŸ¤– LangChain SQL Bot - Fresh Schema")
        print("="*70)
        
        print("\nðŸ”„ ëª¨ë¸ ë¡œë”©...")
        
        base_model_id = "codellama/CodeLlama-7b-Instruct-hf"
        tokenizer = AutoTokenizer.from_pretrained(base_model_id)
        
        base_model = AutoModelForCausalLM.from_pretrained(
            base_model_id,
            torch_dtype=torch.float16,
            device_map="auto",
            load_in_8bit=True
        )
        
        model = PeftModel.from_pretrained(base_model, model_path)
        model = model.merge_and_unload()
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        
        pipe = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
            max_new_tokens=256,
            temperature=0.1,
            return_full_text=False
        )
        
        self.llm = HuggingFacePipeline(pipeline=pipe)
        
        self.databases = {}
        for proj in ["KNIGHTFURY", "FURYX"]:
            uri = os.getenv(f"{proj}_DB_URI")
            if uri:
                self.databases[proj.lower()] = uri.replace("mysql://", "mysql+pymysql://")
        
        print("\nðŸ“š í”„ë¡œì íŠ¸:", ', '.join(self.databases.keys()))
        print("="*70)
        
        self.agents = {}
        self.db_connections = {}
    
    def get_db(self, project):
        """í”„ë¡œì íŠ¸ë³„ DB (ìºì‹œ ì•ˆ í•¨ - í•­ìƒ ìƒˆë¡œ ìƒì„±)"""
        project = project.lower()
        
        uri = self.databases.get(project)
        if not uri:
            raise ValueError(f"í”„ë¡œì íŠ¸ '{project}' ì—†ìŒ")
        
        # ë§¤ë²ˆ ìƒˆë¡œ ìƒì„± (ìºì‹œ ì•ˆ í•¨!)
        return FreshSchemaSQLDatabase.from_uri(uri)
    
    def get_agent(self, project):
        """Agent ìƒì„± (ìºì‹œ ì•ˆ í•¨)"""
        project = project.lower()
        
        # ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±
        db = self.get_db(project)
        
        return create_sql_agent(
            llm=self.llm,
            db=db,
            agent_type="zero-shot-react-description",
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=3,
            max_execution_time=30
        )
    
    def ask(self, project, question):
        """ì§ˆë¬¸ ì²˜ë¦¬"""
        
        print("\n" + "="*70)
        print(f"ðŸ“‚ {project} | ðŸ’¬ {question}")
        print("="*70)
        
        try:
            # ìµœì‹  ìŠ¤í‚¤ë§ˆ í™•ì¸
            db = self.get_db(project)
            tables = db.get_usable_table_names()
            print(f"\nðŸ“Š í…Œì´ë¸”: {len(tables)}ê°œ")
            
            # fury_users ìŠ¤í‚¤ë§ˆ ê°•ì œ ì¶œë ¥
            if 'fury_users' in tables:
                schema = db.get_table_info(['fury_users'])
                print(f"\n{schema}\n")
            
            # Agent ì‹¤í–‰
            agent = self.get_agent(project)
            
            prompt = f"""Answer ONLY this question. Do NOT continue with other questions.

Question: {question}

Steps:
1. Check schema
2. Write SQL
3. Execute
4. Answer
5. STOP

Answer:"""
            
            result = agent.invoke({"input": prompt})
            
            if isinstance(result, dict):
                answer = result.get('output', str(result))
            else:
                answer = str(result)
            
            print("\n" + "="*70)
            print(f"ðŸ’¡ {answer}")
            print("="*70)
            
            return answer
            
        except Exception as e:
            print(f"\nâŒ {e}")
            return None
    
    def verify_count(self, project, table):
        """ì§ì ‘ COUNT í™•ì¸"""
        
        print(f"\nðŸ” [{table}] ì§ì ‘ COUNT í™•ì¸:")
        
        db = self.get_db(project)
        
        sql = f"SELECT COUNT(*) FROM {table}"
        result = db.run(sql)
        
        print(f"âœ… ê²°ê³¼: {result}")
        
        return result

# ì‹¤í–‰
if __name__ == "__main__":
    MODEL_PATH = "./models/sql-generator-spider-plus-company"
    
    bot = LangChainAgentBot(MODEL_PATH)
    
    # ì§ì ‘ COUNT ë¨¼ì € í™•ì¸
    print("\n" + "="*70)
    print("ðŸ§ª ì§ì ‘ COUNT í…ŒìŠ¤íŠ¸")
    print("="*70)
    bot.verify_count("knightfury", "fury_users")
    
    # Agentë¡œ ì§ˆë¬¸
    if len(sys.argv) > 2:
        bot.ask(sys.argv[1], sys.argv[2])
    else:
        bot.ask("knightfury", "How many users are in fury_users table?")
