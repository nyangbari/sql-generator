#!/usr/bin/env python3
# langchain_agent_bot.py
# LangChain Agent with Correct Imports

import os
import sys
import torch
from dotenv import load_dotenv
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from peft import PeftModel
from langchain_huggingface import HuggingFacePipeline
from langchain_community.utilities.sql_database import SQLDatabase
from langchain_community.agent_toolkits.sql.base import create_sql_agent  # ì˜¬ë°”ë¥¸ import!
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from sqlalchemy import inspect

load_dotenv()

class FixedSQLDatabase(SQLDatabase):
    """Read-Only SQL Database with No Caching"""
    
    WRITE_KEYWORDS = [
        'INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 
        'ALTER', 'TRUNCATE', 'REPLACE', 'MERGE'
    ]
    
    def __init__(self, *args, **kwargs):
        kwargs['sample_rows_in_table_info'] = 0
        super().__init__(*args, **kwargs)
        self._sample_rows_in_table_info = 0
    
    def get_table_info_no_throw(self, table_names=None):
        """ìºì‹œ ì—†ì´ í•­ìƒ ìƒˆë¡œ ì¡°íšŒ"""
        
        if table_names is None:
            table_names = self.get_usable_table_names()
        
        inspector = inspect(self._engine)
        
        all_info = []
        
        for table in table_names:
            try:
                columns = inspector.get_columns(table)
                pk = inspector.get_pk_constraint(table)
                pk_cols = pk.get('constrained_columns', [])
                
                create = f"CREATE TABLE {table} (\n"
                
                col_defs = []
                for col in columns:
                    col_def = f"  {col['name']} {col['type']}"
                    
                    if not col['nullable']:
                        col_def += " NOT NULL"
                    
                    if col['name'] in pk_cols:
                        col_def += " PRIMARY KEY"
                    
                    col_defs.append(col_def)
                
                create += ",\n".join(col_defs)
                create += "\n)"
                
                all_info.append(create)
                
            except Exception as e:
                print(f"âš ï¸  {table} ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        result = "\n\n".join(all_info)
        
        print(f"\nðŸ“‹ ì‹¤ì œ ìŠ¤í‚¤ë§ˆ:\n{result}\n")
        
        return result
    
    def run(self, command: str, fetch: str = "all", **kwargs):
        """SQL ì‹¤í–‰"""
        
        sql_upper = command.upper().strip()
        
        for keyword in self.WRITE_KEYWORDS:
            if keyword in sql_upper:
                raise ValueError(f"ðŸš« {keyword} ì°¨ë‹¨!")
        
        if not any(sql_upper.startswith(k) for k in ['SELECT', 'SHOW', 'DESCRIBE', 'EXPLAIN']):
            raise ValueError("ðŸš« SELECTë§Œ í—ˆìš©")
        
        print(f"\nðŸ” [ì‹¤í–‰ SQL]\n{command}\n")
        
        result = super().run(command, fetch=fetch, **kwargs)
        
        print(f"ðŸ“Š [ê²°ê³¼]\n{result}\n")
        
        return result

class LangChainAgentBot:
    def __init__(self, model_path):
        print("="*70)
        print("ðŸ¤– LangChain Agent SQL Bot")
        print("="*70)
        
        print("\nðŸ”„ ëª¨ë¸ ë¡œë”©...")
        
        base_model_id = "codellama/CodeLlama-7b-Instruct-hf"
        tokenizer = AutoTokenizer.from_pretrained(base_model_id)
        
        base_model = AutoModelForCausalLM.from_pretrained(
            base_model_id,
            torch_dtype=torch.float16,
            device_map="auto",
            load_in_8bit=True
        )
        
        model = PeftModel.from_pretrained(base_model, model_path)
        model = model.merge_and_unload()
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        
        pipe = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
            max_new_tokens=256,
            temperature=0.1,
            return_full_text=False
        )
        
        self.llm = HuggingFacePipeline(pipeline=pipe)
        
        # DB
        self.databases = {}
        for proj in ["KNIGHTFURY", "FURYX"]:
            uri = os.getenv(f"{proj}_DB_URI")
            if uri:
                self.databases[proj.lower()] = uri.replace("mysql://", "mysql+pymysql://")
        
        print("\nðŸ“š í”„ë¡œì íŠ¸:", ', '.join(self.databases.keys()))
        print("="*70)
    
    def create_fresh_agent(self, project):
        """ìƒˆ Agent ìƒì„±"""
        
        uri = self.databases.get(project.lower())
        if not uri:
            raise ValueError(f"í”„ë¡œì íŠ¸ '{project}' ì—†ìŒ")
        
        # ìƒˆ DB
        db = FixedSQLDatabase.from_uri(uri, sample_rows_in_table_info=0)
        
        print(f"\nðŸ”— [{project}] Agent ìƒì„± ì¤‘...")
        
        tables = db.get_usable_table_names()
        print(f"ðŸ“Š í…Œì´ë¸”: {len(tables)}ê°œ")
        
        # fury_users ìŠ¤í‚¤ë§ˆ í™•ì¸
        if 'fury_users' in tables:
            db.get_table_info_no_throw(['fury_users'])
        
        # Agent ìƒì„±
        agent = create_sql_agent(
            llm=self.llm,
            db=db,
            agent_type="zero-shot-react-description",
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=3,
            max_execution_time=30
        )
        
        print("âœ… Agent ì¤€ë¹„!")
        
        return agent, db
    
    def ask(self, project, question):
        """ì§ˆë¬¸ ì²˜ë¦¬"""
        
        print("\n" + "="*70)
        print(f"ðŸ“‚ {project} | ðŸ’¬ {question}")
        print("="*70)
        
        try:
            # ìƒˆ Agent
            agent, db = self.create_fresh_agent(project)
            
            # ìŠ¤í‚¤ë§ˆ ëª…ì‹œ
            tables = db.get_usable_table_names()
            main_tables = ['fury_users'] if 'fury_users' in tables else tables[:2]
            schema = db.get_table_info_no_throw(main_tables)
            
            prompt = f"""Answer this ONE question only.

DATABASE SCHEMA:
{schema}

RULES:
1. Use ONLY the columns from schema above
2. For COUNT: SELECT COUNT(*) FROM table_name
3. Execute and report ACTUAL result
4. After answering, STOP

Question: {question}

Answer:"""
            
            print("\nðŸ¤” Agent ì‹¤í–‰ ì¤‘...\n")
            
            result = agent.invoke({"input": prompt})
            
            if isinstance(result, dict):
                answer = result.get('output', str(result))
            else:
                answer = str(result)
            
            print("\n" + "="*70)
            print(f"ðŸ’¡ ë‹µë³€:")
            print(answer)
            print("="*70)
            
            return answer
            
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜: {e}")
            print("="*70)
            return None
    
    def verify(self, project, table='fury_users'):
        """ì§ì ‘ ê²€ì¦"""
        
        uri = self.databases.get(project.lower())
        db = FixedSQLDatabase.from_uri(uri, sample_rows_in_table_info=0)
        
        print(f"\nðŸ” [{table}] ì§ì ‘ COUNT:")
        result = db.run(f"SELECT COUNT(*) FROM {table}")
        print(f"âœ… {result}")
        
        return result

# ì‹¤í–‰
if __name__ == "__main__":
    MODEL_PATH = "./models/sql-generator-spider-plus-company"
    
    bot = LangChainAgentBot(MODEL_PATH)
    
    # ì§ì ‘ ê²€ì¦
    print("\n" + "="*70)
    print("ðŸ§ª ì§ì ‘ ê²€ì¦")
    print("="*70)
    bot.verify("knightfury", "fury_users")
    
    # Agent
    if len(sys.argv) > 2:
        bot.ask(sys.argv[1], sys.argv[2])
    else:
        bot.ask("knightfury", "How many users are in fury_users?")
