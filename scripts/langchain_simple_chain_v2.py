#!/usr/bin/env python3
# langchain_simple_chain_v2.py
# ëª¨ë“  í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì œê³µ ë²„ì „

import os
import sys
import torch
from dotenv import load_dotenv
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from peft import PeftModel
from langchain_huggingface import HuggingFacePipeline
from langchain_community.utilities.sql_database import SQLDatabase
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from sqlalchemy import inspect

load_dotenv()

class SimpleSQLChain:
    def __init__(self, model_path):
        print("="*70)
        print("ğŸ¤– LangChain Simple Chain v2")
        print("   - ëª¨ë“  í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì œê³µ")
        print("="*70)
        
        print("\nğŸ”„ ëª¨ë¸ ë¡œë”©...")
        
        base_model_id = "codellama/CodeLlama-7b-Instruct-hf"
        tokenizer = AutoTokenizer.from_pretrained(base_model_id)
        
        base_model = AutoModelForCausalLM.from_pretrained(
            base_model_id,
            torch_dtype=torch.float16,
            device_map="auto",
            load_in_8bit=True
        )
        
        model = PeftModel.from_pretrained(base_model, model_path)
        model = model.merge_and_unload()
        
        print("âœ… ëª¨ë¸ ë¡œë“œ!")
        
        pipe = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
            max_new_tokens=200,
            temperature=0.1,
            return_full_text=False
        )
        
        self.llm = HuggingFacePipeline(pipeline=pipe)
        
        self.databases = {}
        for proj in ["KNIGHTFURY", "FURYX"]:
            uri = os.getenv(f"{proj}_DB_URI")
            if uri:
                self.databases[proj.lower()] = uri.replace("mysql://", "mysql+pymysql://")
        
        print("\nğŸ“š í”„ë¡œì íŠ¸:", ', '.join(self.databases.keys()))
        print("="*70)
    
    def get_schema(self, db, table_names):
        """ìŠ¤í‚¤ë§ˆ (ê°„ë‹¨ ë²„ì „)"""
        inspector = inspect(db._engine)
        
        schema = ""
        for table in table_names:
            columns = inspector.get_columns(table)
            
            schema += f"\nTable: {table}\n"
            schema += "Columns: "
            schema += ", ".join([col['name'] for col in columns])
            schema += "\n"
        
        return schema
    
    def ask(self, project, question):
        print("\n" + "="*70)
        print(f"ğŸ“‚ {project} | ğŸ’¬ {question}")
        print("="*70)
        
        uri = self.databases.get(project.lower())
        if not uri:
            print("âŒ í”„ë¡œì íŠ¸ ì—†ìŒ")
            return None
        
        try:
            db = SQLDatabase.from_uri(uri, sample_rows_in_table_info=0)
            
            # ëª¨ë“  í…Œì´ë¸” ëª©ë¡
            all_tables = db.get_usable_table_names()
            print(f"\nğŸ“Š ì „ì²´ í…Œì´ë¸”: {len(all_tables)}ê°œ")
            
            # fury_ ë¡œ ì‹œì‘í•˜ëŠ” í…Œì´ë¸”ë§Œ (ê´€ë ¨ í…Œì´ë¸”)
            relevant_tables = [t for t in all_tables if t.startswith('fury_')]
            
            if not relevant_tables:
                relevant_tables = all_tables[:10]  # ì²˜ìŒ 10ê°œ
            
            print(f"ğŸ“‹ ì‚¬ìš©í•  í…Œì´ë¸”: {len(relevant_tables)}ê°œ")
            print(f"   {', '.join(relevant_tables[:5])}...")
            
            # ìŠ¤í‚¤ë§ˆ (ê°„ë‹¨ ë²„ì „ - í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª…ë§Œ)
            schema = self.get_schema(db, relevant_tables)
            
            print(f"\nğŸ“„ ìŠ¤í‚¤ë§ˆ:\n{schema[:500]}...")
            
            # Step 1: SQL ìƒì„±
            print("\nğŸ”„ Step 1: SQL ìƒì„±...")
            
            sql_prompt = PromptTemplate.from_template(
                """You have access to these tables:

{schema}

Generate a SQL query to answer: {question}

Choose the correct table based on the question.
Return ONLY the SQL query.

SQL:"""
            )
            
            sql_chain = sql_prompt | self.llm | StrOutputParser()
            
            sql = sql_chain.invoke({
                "schema": schema,
                "question": question
            })
            
            # SQL ì •ë¦¬
            sql = sql.strip()
            sql = sql.replace('```sql', '').replace('```', '').strip()
            sql = sql.split('\n')[0] if '\n\n' in sql else sql
            
            # ë³´ì•ˆ
            sql_upper = sql.upper()
            if any(kw in sql_upper for kw in ['INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 'ALTER']):
                print("ğŸš« ìœ„í—˜í•œ SQL!")
                return None
            
            print(f"\nğŸ’¾ SQL:\n{sql}")
            
            # Step 2: ì‹¤í–‰
            print("\nğŸ”„ Step 2: ì‹¤í–‰...")
            result = db.run(sql)
            
            print(f"\nğŸ“Š ê²°ê³¼:\n{result}")
            
            # Step 3: ë‹µë³€
            print("\nğŸ”„ Step 3: ë‹µë³€ ìƒì„±...")
            
            answer_prompt = PromptTemplate.from_template(
                """Question: {question}
SQL: {sql}
Result: {result}

Provide a natural language answer in Korean.

Answer:"""
            )
            
            answer_chain = answer_prompt | self.llm | StrOutputParser()
            
            answer = answer_chain.invoke({
                "question": question,
                "sql": sql,
                "result": result
            })
            
            answer = answer.strip()
            
            print("\n" + "="*70)
            print(f"ğŸ’¡ ë‹µë³€:")
            print(answer)
            print("="*70)
            
            return answer
            
        except Exception as e:
            print(f"\nâŒ {e}")
            import traceback
            traceback.print_exc()
            return None

if __name__ == "__main__":
    MODEL_PATH = "./models/sql-generator-spider-plus-company"
    
    bot = SimpleSQLChain(MODEL_PATH)
    
    if len(sys.argv) > 2:
        bot.ask(sys.argv[1], sys.argv[2])
    else:
        # í…ŒìŠ¤íŠ¸
        bot.ask("knightfury", "ì–¼ë§ˆë‚˜ ë§ì€ ë¯¸ì…˜ì´ ìˆì–´?")
